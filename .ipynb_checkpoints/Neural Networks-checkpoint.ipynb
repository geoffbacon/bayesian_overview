{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: There and Back Again...and Again...and Again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talked last week about how Support Vector Machines were supposed to revolutionize machine learning when they first came out, but are hardly talked about anymore. The algorithm that is actually revolutionizing machine learning is the neural network. The nice thing about Support Vector Machines is that they can be used to create nonlinear classification boundaries. They do this by transforming the input data to a space where the boundary is linear and then untransforming the predicted boundary. Thus, it automates feature engineering for you. Neural Nets also do this, but in a much more straight forward way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\">\n",
    "Taken from the MIT CS231n <a href=\"http://cs231n.github.io/neural-networks-1/\">course page</a>. <a href=\"https://github.com/cs231n/cs231n.github.io/blob/master/LICENSE\">LICENSE</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each circle in the diagram is called a neuron or node. Each feature in your input data gets a node. Each class in your output gets a node. In the above picture, there are two outputs, so it's a binary classification problem. To get from the input to the output you go through any number of hidden layers with any number of nodes; the numbers are hyperparameters. You can see that all the input nodes contribute to each hidden layer node somehow. The weights for how much each input contributes are the parameters to be optimized. It's called a hidden layer because the user doesn't get to see the parameters without purposefully looking for them. Thus, feature engineering is automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets are mainly used for classification, so that's the problem I'm going to focus on. I'll explain how it can be modified later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication: A Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to figure out how to code an algorithm, it is helpful to keep track of all the dimensions of the matrices and vectors you're working with. Remember what happens with the dimensions:\n",
    "$$ [n \\times m][m \\times p] = [n \\times p] $$\n",
    "The inner two dimensions have to be the same; the operation is not defined otherwise. The product matrix then takes the outer dimensions. For example, take these two vectors (1D matrices):\n",
    "$$ \\mathbf{A} =  \\begin{bmatrix}\n",
    "                    a_1 \\newline a_2 \\newline a_3\n",
    "                 \\end{bmatrix},\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "                b_1 \\newline b_2 \\newline b_3\n",
    "             \\end{bmatrix} $$\n",
    "They are both $[3 \\times 1]$ vectors. They can't be multiplied together as is, but if you take the transpose of one, they can be. This gives us two possibilities:\n",
    "$$ \\mathbf{A^TB} = a_1b_1 + a_2b_2 + a_3b_3 \\\\\n",
    "   \\mathbf{AB^T} = \\begin{bmatrix}\n",
    "                        a_1b_1 & a_1b_2 & a_1b_3 \\\\\n",
    "                        a_2b_1 & a_2b_2 & a_2b_3 \\\\\n",
    "                        a_3b_1 & a_3b_2 & a_3b_3\n",
    "                   \\end{bmatrix} \\\\ $$\n",
    "Notice that the answers are quite different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the above looks like as a summation:\n",
    "$$ (\\mathbf{AB})_{ij} = \\sum_{k=1}^m A_{ik}B_{kj} $$\n",
    "where $i$ goes from 1 to $n$ and $j$ goes from 1 to $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Logistic Regression: A Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's review the math behind binary logistic regression. I'll be using the notation from <a href=\"https://www.coursera.org/learn/machine-learning/home/welcome\">Machine Learning by Andrew Ng</a> on Coursera, except for one change. I'm going to treat the parameter and feature vectors as row vectors, while Andrew Ng treats them as column vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a binary classification problem with classes 0 and 1. You have a hypothesis about your data, $ h_{\\theta}(x) $, which is the probability that the item with feature $x$ is in class 1. The probability of class 0 is $1 - h_{\\theta}(x) $. What does this hypothesis look like? We need a function that can take any real number and squish it into the interval [0,1]. This is called the activation function. One such function is the sigmoid, or logistic, function:\n",
    "$$ g(z) = \\frac {1}{1+e^{-z}} $$\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/sigmoid.jpeg\">\n",
    "Taken from the MIT CS231n <a href=\"http://cs231n.github.io/neural-networks-1/\">course page</a>. <a href=\"https://github.com/cs231n/cs231n.github.io/blob/master/LICENSE\">LICENSE</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $ h_{\\theta}(x) = g(z) \\geq 0.5$, we predict class 1. When $ h_{\\theta}(x) = g(z) < 0.5$, we predict class 0. Well, what is $z$? If we have $n$ features:\n",
    "$$ z = \\theta_0 + \\theta_1x_1 + ... + \\theta_nx_n = \\begin{bmatrix}1(=x_0) &  x_1 &  ...  \\hspace{2em}  x_n\\end{bmatrix}\\begin{bmatrix} \\theta_0 \\newline \\theta_1 \\newline \\vdots \\newline \\theta_n\\end{bmatrix}= \\boldsymbol{x \\theta}^T $$\n",
    "where $\\theta$ and $x$ are column vectors. $\\theta$ are the parameters to optimize. $\\theta_0$ is called the bias term and it acts much like an intercept term in linear regression. Just like $b$ allows you to shift a line along the y axis, $\\theta_0$ allows the activation function to shift to get a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function for this problem is:\n",
    "$$ J(\\boldsymbol{\\theta}) = - \\frac{1}{m} \\displaystyle \\sum_{i=1}^m [y^{(i)}\\log (h_\\theta (\\mathbf{x}^{(i)})) + (1 - y^{(i)})\\log (1 - h_\\theta(\\mathbf{x}^{(i)}))] $$\n",
    "where $m$ is the number of observations. Basically, if you think about a DataFrame, $i$ is the row and $m$ is the total number of rows. Then $\\mathbf{x}$ is $[m \\times n]$ (without the added bias variable) and $\\mathbf{y}$ is $[m \\times 1]$. In vectorized notation, this is:\n",
    "$$ J(\\boldsymbol{\\theta}) = - \\frac{1}{m} [\\mathbf{y}^T \\log (g(\\boldsymbol{x \\theta}^T)) + (\\mathbf{1 - y}^T) \\log (g(1 - \\boldsymbol{x \\theta}^T))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add a regularization term:\n",
    "$$ J(\\boldsymbol{\\theta}) = - \\frac{1}{m} \\displaystyle \\sum_{i=1}^m [y^{(i)}\\log (h_\\theta (\\mathbf{x}^{(i)})) + (1 - y^{(i)})\\log (1 - h_\\theta(\\mathbf{x}^{(i)}))] + \\frac{\\lambda}{2m} \\sum^{n}_{j=1} \\theta_j$$\n",
    "**Note:** The bias term is not included!!!  \n",
    "\n",
    "And in vector notation:\n",
    "$$ J(\\boldsymbol{\\theta}) = - \\frac{1}{m} [\\mathbf{y}^T \\log (g(\\boldsymbol{x \\theta}^T)) + (\\mathbf{1 - y}^T) \\log (g(1 - \\boldsymbol{x \\theta}^T))] + \\frac{\\lambda}{2m}\\boldsymbol\\theta_{j \\neq 0}\\boldsymbol\\theta_{j \\neq 0}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can minimize the cost function with the solver of your choice. Often times, the solver asks for a cost function and a derivative, so here's the derivative:\n",
    "$$ \\frac{\\partial}{\\partial\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) = \\frac{1}{m} \\sum_{i=1}^m  (h_\\theta(\\mathbf{x}^{(i)}) - y^{(i)}) \\mathbf{x}_j^{(i)} \\\\\n",
    "= \\frac{1}{m} \\mathbf{x}^T(g(\\boldsymbol{x \\theta}^T - \\mathbf{y}))\n",
    "$$\n",
    "Note that there are $n+1$ derivatives, one for each feature and one for the bias term. To add regularization to this, add $ \\frac {\\lambda}{m}\\theta_j $ to the jth derivative, except for the bias term. Don't add anything to the bias term. There's really not a good way to notate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest solver to use is gradient descent and it's exactly what it sounds like. If you imagine a graph of the cost function vs the parameters, the minimum is the bottom of the valley in the graph. You have to descend the slope, or gradient, to get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5b/Gradient_descent_method.png\">\n",
    "By Роман Сузи (Сгенерирован программой, повернут вручную) [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the algorithm, the estimates for $\\boldsymbol\\theta$ are updated according to their gradients, the cost function is recalculated, and this is repeated until convergence. Here are the equations for updating $\\boldsymbol\\theta$:\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\boldsymbol\\theta) $$\n",
    "$\\alpha$ is called the learning rate, and it's a hyperparameter that determines how fast the algorithm converges. If it is too large, the algorithm could keep missing the minimum and never converge. If it's too small, the algorithm could take a long time to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakfast: Neural Nets from scratch\n",
    "Neural nets just apply logistic regression at every neuron past the input layer. To keep things simple, I'm going to stick with a binary classification problem modified from <a href=\"http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\">this</a> blog post. So, let's use scikit learn's <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html\">```make_moons()```</a> function to get some binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a dataset\n",
    "np.random.seed(0)\n",
    "X, y = sklearn.datasets.make_moons(200, noise=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 200 observations and 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that numpy doesn't distinguish between row and column vectors by default. Everything is just a 1D array. This could get confusing when delving into the math, so let's turn it into a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.reshape(y, (200,1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Daily Caloric Intake</th>\n",
       "      <th>Hobbit?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743461</td>\n",
       "      <td>0.464656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.657557</td>\n",
       "      <td>-0.632032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.158789</td>\n",
       "      <td>0.255845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.088752</td>\n",
       "      <td>-0.396943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.768052</td>\n",
       "      <td>-0.254432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height  Daily Caloric Intake  Hobbit?\n",
       "0  0.743461              0.464656        0\n",
       "1  1.657557             -0.632032        1\n",
       "2 -0.158789              0.255845        1\n",
       "3 -1.088752             -0.396943        0\n",
       "4  1.768052             -0.254432        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's what it might look like in a DataFrame\n",
    "data = np.column_stack((X, y))\n",
    "data = pd.DataFrame(data, columns=[\"Height\", \"Daily Caloric Intake\", \"Hobbit?\"])\n",
    "data[\"Hobbit?\"] = data[\"Hobbit?\"].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1150d60f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlCVaOJRSSlny/+IjLyur3MNmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150d6358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot it\n",
    "plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, it's easy to see that the division between hobbits and not hobbits is not linear, so logistic regression by itself won't work without some feature engineering. That's why we throw it into a neural net and let it do the engineering for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "First, we start with our inputs and calculate forward to the output neurons using initial guesses for all $\\boldsymbol\\theta$'s. In our example, we'll have one hidden layer with 5 neurons. \n",
    "<img src=\"nn-from-scratch-3-layer-network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarity's sake, the bias terms are not usually included in these types of diagrams. The $\\mathbf a$'s are the activation units. $\\mathbf a^{(1)}$ is just $\\mathbf X$, plus a column of one's for the bias variable. Input 1 is \"Height\" and Input 2 is \"Daily Caloric Intake.\" In a single logistic regression, $\\boldsymbol\\theta^{(1)}$ would be $[1 \\times 3]$. But, we're doing 5 logistic regressions, one for each neuron in the hidden layer, so $\\boldsymbol\\theta^{(1)}$ is $[5 \\times 3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hl_nodes = 5\n",
    "np.random.seed(37)\n",
    "theta1 = np.random.randn(n_hl_nodes, n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05446361,  0.67430807,  0.34664703],\n",
       "       [-1.30034617,  1.51851188,  0.98982371],\n",
       "       [ 0.2776809 , -0.44858935,  0.96196624],\n",
       "       [-0.82757864,  0.53465707,  1.22838619],\n",
       "       [ 0.51959233, -0.06335482, -0.03479336]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When initializing $\\boldsymbol\\theta$, it is important to break symmetry. If $\\boldsymbol\\theta$ is symmetric, then some of the nodes in the hidden layer will turn out to be the same and the algorithm will not be as efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, $\\mathbf a^{(2)}$ is just $g(\\boldsymbol{x \\theta}^T)$ (with bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our activation function\n",
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add bias to X\n",
    "a1 = np.column_stack((np.ones_like(y), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.74346118,  0.46465633],\n",
       "       [ 1.        ,  1.65755662, -0.63203157],\n",
       "       [ 1.        , -0.15878875,  0.25584465],\n",
       "       [ 1.        , -1.088752  , -0.39694315],\n",
       "       [ 1.        ,  1.768052  , -0.25443213]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape #added a column, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z1 = np.dot(a1, theta1.T)\n",
    "a2 = sigmoid(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64746846,  0.57163776,  0.59656091,  0.53511598,  0.61214165],\n",
       "       [ 0.69933818,  0.6436114 ,  0.25466698,  0.32789236,  0.6074411 ],\n",
       "       [ 0.48179596,  0.21615295,  0.64451745,  0.35475558,  0.62732328],\n",
       "       [ 0.28369283,  0.03400889,  0.59489474,  0.13041583,  0.64620085],\n",
       "       [ 0.74068847,  0.75632187,  0.31860208,  0.45144895,  0.60262873]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.shape #shape is (m, n_hl_nodes), check!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, we've turned our 2 feature problem into a 5 feature problem now. The next step is to use $\\mathbf a^{(2)}$ like it's our new $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "np.random.seed(42)\n",
    "theta2 = np.random.randn(n_classes, n_hl_nodes+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986, -0.23415337,\n",
       "        -0.23413696],\n",
       "       [ 1.57921282,  0.76743473, -0.46947439,  0.54256004, -0.46341769,\n",
       "        -0.46572975]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add bias to a2\n",
    "a2 = np.column_stack((np.ones_like(y), a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.64746846,  0.57163776,  0.59656091,  0.53511598,\n",
       "         0.61214165],\n",
       "       [ 1.        ,  0.69933818,  0.6436114 ,  0.25466698,  0.32789236,\n",
       "         0.6074411 ],\n",
       "       [ 1.        ,  0.48179596,  0.21615295,  0.64451745,  0.35475558,\n",
       "         0.62732328],\n",
       "       [ 1.        ,  0.28369283,  0.03400889,  0.59489474,  0.13041583,\n",
       "         0.64620085],\n",
       "       [ 1.        ,  0.74068847,  0.75632187,  0.31860208,  0.45144895,\n",
       "         0.60262873]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.shape #added a column, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z2 = np.dot(a2, theta2.T)\n",
    "a3 = sigmoid(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.shape #shape is (m, n_classes), check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80492916,  0.83178466],\n",
       "       [ 0.72824652,  0.82010629],\n",
       "       [ 0.78947625,  0.85076425],\n",
       "       [ 0.76918631,  0.85098359],\n",
       "       [ 0.75447047,  0.81390075]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf a^{(3)}$ is $ h_{\\theta}(x)$. You might also realize it's not the same size as $y$. What we need to do is make a $y_{big}$ matrix that marks a 1 in the row under the column that corresponds to the class. Say our first observation is a hobbit. The first row gets a 1 in the hobbit column. The second observation is not a hobbit, so the second row gets a 1 in the not hobbit column. Since we're doing a binary problem, this works out to $[y, 1-y]$, but it can be generalized to any number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_big = np.column_stack((y, 1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_big.shape #same shape as a3, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_big[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to calculate the cost. We need to calculate it per class, which means matrix math won't quite do the trick. We have to loop over the columns. First without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "J = 0\n",
    "for i in range(n_classes):\n",
    "    J += -1 / m * (np.dot(y_big[:,i].T,np.log(a3[:,i])) + np.dot((1 - y_big[:,i]).T, np.log(1 - a3[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9529544947757143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_lambda = 0.01 # remember that lambda is a reserved word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "J += reg_lambda / (2 * m) * (np.dot(theta1[:,2:].flatten().T, theta1[:,2:].flatten()) + # remove the bias\n",
    "                             np.dot(theta2[:,2:].flatten().T, theta2[:,2:].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9531377608620535"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation\n",
    "We've got our first predictions. Now we need to compare them to our labels and use this to update our parameters. This isn't quite as simple as just applying your solver to the layers. We'll go through these step by step. The first thing to do is figure out how to calculate our residuals, $\\boldsymbol\\delta$. $\\boldsymbol\\delta^{(3)}$ is easy:\n",
    "$$ \\boldsymbol\\delta^{(3)} = \\mathbf a^{(3)} - \\mathbf y_{big} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3 = a3 - y_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.shape #same shape as a3 and y_big, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80492916, -0.16821534],\n",
       "       [-0.27175348,  0.82010629],\n",
       "       [-0.21052375,  0.85076425],\n",
       "       [ 0.76918631, -0.14901641],\n",
       "       [-0.24552953,  0.81390075]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining layers, except for the input layer, the residual is calculated as follows:\n",
    "$$ \\boldsymbol\\delta^{(l)} = \\boldsymbol\\delta^{(l+1)} \\boldsymbol\\theta^{(l)} .* g'(\\mathbf z^{(l)}) $$\n",
    "where $l$ is the layer number and I'm using $.*$ to emphasize that this is element-wise multiplication, not matrix multiplication. Turns out that $g'(\\mathbf z^{(l)})$ is just $\\mathbf a^{(l)} .* (1 - \\mathbf a^{(l)})$, so:\n",
    "$$ \\boldsymbol\\delta^{(l)} = \\boldsymbol\\delta^{(l+1)} \\boldsymbol\\theta^{(l)} .* \\mathbf a^{(l)} .* (1 - \\mathbf a^{(l)}) $$\n",
    "\n",
    "There is no residual for the input layer ($l=1$), so we only have $\\boldsymbol\\delta^{(2)}$ left to calculate:\n",
    "$$ \\boldsymbol\\delta^{(2)} = \\boldsymbol\\delta^{(3)} \\boldsymbol\\theta^{(2)} .* \\mathbf a^{(2)} .* (1 - \\mathbf a^{(2)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = np.dot(d3, theta2[:,1:]) * a2[:,1:] * (1 - a2[:,1:]) #remember, no bias terms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape #same shape as a2 without bias, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05486913,  0.14699824,  0.27308643, -0.02749444, -0.02614534],\n",
       "       [ 0.14023616, -0.1286868 ,  0.00589712, -0.06973226, -0.07590553],\n",
       "       [ 0.17027748, -0.09077526,  0.03229526, -0.07896374, -0.08110947],\n",
       "       [-0.04485103,  0.01866511,  0.26283959, -0.01259399, -0.02530735],\n",
       "       [ 0.12648971, -0.09973018,  0.01468456, -0.07916755, -0.07700558]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to turn this into an overal gradient that we can feed to a solver. First, without regularization, the equation is:\n",
    "$$\\dfrac{\\partial J(\\Theta)}{\\partial \\Theta_{i,j}^{(l)}} = \\frac{1}{m}\\sum_{t=1}^m a_j^{(t)(l)} {\\delta}_i^{(t)(l+1)}$$\n",
    "\n",
    "Vectorized:\n",
    "$$ \\dfrac{\\partial J(\\boldsymbol\\Theta)}{\\partial \\boldsymbol\\Theta^{(l)}} = \\frac{1}{m} \\sum^l \\mathbf a^{(l)} \\boldsymbol\\delta^{(l+1)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D1 = np.dot(d2.T, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1.shape #same shape as theta1, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.35964512,  13.11345605,  -5.69031915],\n",
       "       [  0.85114796,  -7.52654685,   9.83311069],\n",
       "       [ 24.74662027,   3.16965899,  13.87266761],\n",
       "       [ -9.98438012,  -7.17567142,  -1.08518148],\n",
       "       [-10.58193359,  -7.57139698,  -0.88206638]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D2 = np.dot(d3.T, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2.shape #same shape as theta2, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 57.34865402,  28.62466904,  18.59985951,  47.19066651,\n",
       "         30.83091062,  35.87842329],\n",
       "       [ 67.26123464,  43.60770823,  35.61173322,  24.93102975,\n",
       "         24.80697748,  41.13404715]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding regularization is a bit tricky to notate again, so I'll say it in words. You want to add up the $\\theta$'s except for the bias. Remember that the bias terms are all in the first columns. So, the easy thing to do is copy the $\\boldsymbol\\theta$'s, set the first columns to zero, multiply by $\\lambda$, then add those to the $\\mathbf D$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_theta1 = theta1.copy() * reg_lambda\n",
    "reg_theta1[:,0] = 0\n",
    "reg_theta2 = theta2.copy() * reg_lambda\n",
    "reg_theta2[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.00674308,  0.00346647],\n",
       "       [ 0.        ,  0.01518512,  0.00989824],\n",
       "       [ 0.        , -0.00448589,  0.00961966],\n",
       "       [ 0.        ,  0.00534657,  0.01228386],\n",
       "       [ 0.        , -0.00063355, -0.00034793]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_theta1 #check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.00138264,  0.00647689,  0.0152303 , -0.00234153,\n",
       "        -0.00234137],\n",
       "       [ 0.        ,  0.00767435, -0.00469474,  0.0054256 , -0.00463418,\n",
       "        -0.0046573 ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_theta2 #check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D1 = D1 + reg_theta1\n",
    "D2 = D2 + reg_theta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing\n",
    "Now that we have our cost function and our derivative, we can use gradient descent to solve it. Here's what the first update looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "theta1 += -alpha * D1\n",
    "theta2 += -alpha * D2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy. Now we just keep going until the cost stops changing by more than our tolerance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's collect the forward propagation steps\n",
    "def forward_propagation(a1, theta1, theta2, y_big):\n",
    "    z1 = np.dot(a1, theta1.T)\n",
    "    a2 = sigmoid(z1)\n",
    "    a2 = np.column_stack((np.ones_like(y), a2))\n",
    "    z2 = np.dot(a2, theta2.T)\n",
    "    a3 = sigmoid(z2)\n",
    "    J = 0\n",
    "    for i in range(n_classes):\n",
    "        J += -1 / m * (np.dot(y_big[:,i].T,np.log(a3[:,i])) + np.dot((1 - y_big[:,i]).T, np.log(1 - a3[:,i])))\n",
    "        J += reg_lambda / (2 * m) * (np.dot(theta1[:,2:].flatten().T, theta1[:,2:].flatten()) + # remove the bias\n",
    "                                     np.dot(theta2[:,2:].flatten().T, theta2[:,2:].flatten()))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's collect the back propagation steps\n",
    "def back_propagation(a3, y_big, theta2, a2, a1, theta1, reg_lambda):\n",
    "    d3 = a3 - y_big\n",
    "    d2 = np.dot(d3, theta2[:,1:]) * a2[:,1:] * (1 - a2[:,1:]) #remember, no bias terms!\n",
    "    D1 = np.dot(d2.T, a1)\n",
    "    D2 = np.dot(d3.T, a2)\n",
    "    reg_theta1 = theta1.copy() * reg_lambda\n",
    "    reg_theta1[:,0] = 0\n",
    "    reg_theta2 = theta2.copy() * reg_lambda\n",
    "    reg_theta2[:,0] = 0\n",
    "    D1 = D1 + reg_theta1\n",
    "    D2 = D2 + reg_theta2\n",
    "    \n",
    "    return D1, D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tolerance = 0.0001\n",
    "delta = 1\n",
    "old_J = J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9531377608620535"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.90152357823\n",
      "1.85184392232\n",
      "1.80437162543\n",
      "1.75919740616\n",
      "1.71641260072\n",
      "1.67610856592\n",
      "1.63837602369\n",
      "1.60330435317\n",
      "1.57098083842\n",
      "1.54148988232\n",
      "1.51491219937\n",
      "1.49132400187\n",
      "1.47079619567\n",
      "1.45339360282\n",
      "1.43917422884\n",
      "1.42818859199\n",
      "1.42047913136\n",
      "1.41607970863\n",
      "1.41501521609\n",
      "1.41730130081\n"
     ]
    }
   ],
   "source": [
    "#again and again and again\n",
    "while delta > tolerance:\n",
    "    #there\n",
    "    J = forward_propagation(a1, theta1, theta2, y_big)\n",
    "    \n",
    "    #and back\n",
    "    D1, D2 = back_propagation(a3, y_big, theta2, a2, a1, theta1, reg_lambda)\n",
    "    \n",
    "    theta1 += -alpha * D1\n",
    "    theta2 += -alpha * D2\n",
    "    \n",
    "    delta = old_J - J\n",
    "    old_J = J\n",
    "    print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the cost function isn't quite minimized. This is the down side of gradient descent; it tends to overshoot. We could spend a bit more time trying to debug this (which will probably involve rearranging the loop)...or you get the gist of it and we can move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification\n",
    "We made several choices in our implemetation: the activation function, the cost function, and the solver. Any of these can be changed to suit your purposes. For example, you can use the sum of squares as the cost function to use neural nets for regression. The blog post I referenced used a different function in the final layer than for the hidden layers. The catch is that you have to rederive all the propagation steps appropriately...or find someone who's done that already. ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second breakfast: Prebaked neural nets\n",
    "There are quite a few Python modules that can do neural nets. I'm just going to show scikit learn for consistency. Unless you have a GPU, this should be good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to do what we did from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=0.01, hidden_layer_sizes=(5,), #alpha is our lambda!\n",
    "                    activation='logistic', learning_rate_init=0.0005, \n",
    "                    random_state=0) #we used several seeds, so I'll use the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.01, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "       learning_rate_init=0.0005, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLPClassifier likes 1D arrays\n",
    "y = y.reshape(m)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are parameters for the activation function and the solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a more interesting example using the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits\">digits dataset</a>. It consists of pictures of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115444048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD/CAYAAADYIcuOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n46a71ACDLjXAoEsNMOhSAwy61ID/B+1N8jXyZTznAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150d63c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "digits = load_digits()\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50841750841750843"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Let's change some parameters to try to get it to converge. Let's use the default solver (adam), the default activation function (relu), and two hidden layers with 10 nodes each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(alpha=0.01, hidden_layer_sizes=(10, 10), # the numbers in the tuple are how many nodes in a layer\n",
    "                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80639730639730645"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are these Convolutional Neural Networks that I keep hearing about?\n",
    "CNNs are appied to images most often. As such, they require an enormous amount of computational power. Don't try them without a GPU. Just don't. The actual neural network part of CNNs is the same as above. There's just a gazillion preprocessing steps that the images go through before they get to the input layer. More on this later, hopefully..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
